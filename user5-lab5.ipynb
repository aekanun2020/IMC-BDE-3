{"cells":[{"cell_type":"code","execution_count":13,"id":"0712dec4","metadata":{},"outputs":[],"source":["emp = [\n","    (10, \"AAA\", \"dept1\", 1000, \"2019-02-01 15:12:13\"),\n","    (8, \"BBB\", \"dept1\", 1100, \"2018-04-01 05:12:03\"),\n","    (6, \"CCC\", \"dept1\", 3000, \"2017-06-05 01:02:13\"),\n","    (13, \"DDD\", \"dept1\", 1500, \"2019-08-10 10:52:53\"),\n","    (2, \"EEE\", \"dept2\", 8000, \"2016-01-11 05:52:43\"),\n","    (1, \"FFF\", \"dept2\", 7200, \"2015-04-14 19:32:33\"),\n","    (11, \"GGG\", \"dept3\", 7100, \"2019-02-21 15:42:43\"),\n","    (5, \"HHH\", \"dept3\", 3700, \"2016-09-25 15:32:33\"),\n","    (7, \"III\", \"dept3\", 4500, \"2017-10-15 15:22:23\"),\n","    (9, \"JJJ\", \"dept5\", 3400, \"2018-12-17 15:14:17\"),\n","    (4, \"KKK\", \"dept5\", 3400, \"2016-09-11 05:52:43\"),\n","    (3, \"LLL\", \"dept5\", 3400, \"2016-09-11 00:00:00\"),\n","    (12, \"MMM\", \"dept3\", 7100, \"2019-02-28 15:42:43\")\n","]"]},{"cell_type":"code","execution_count":14,"id":"a2c7de33","metadata":{},"outputs":[],"source":["import pyspark.sql.functions as F"]},{"cell_type":"code","execution_count":15,"id":"0a69146a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- dept: string (nullable = true)\n"," |-- salary: long (nullable = true)\n"," |-- date: string (nullable = true)\n","\n"]}],"source":["emp_df = spark.createDataFrame(emp, ['id', 'name', 'dept', 'salary', 'date'])\n","emp_df.printSchema()"]},{"cell_type":"code","execution_count":16,"id":"a3549305","metadata":{},"outputs":[],"source":["correctedType_df = (\n","    emp_df\n","    .withColumn('date', F.to_timestamp('date', 'yyyy-MM-dd HH:mm:ss'))\n",")"]},{"cell_type":"code","execution_count":17,"id":"a4f04c1b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- dept: string (nullable = true)\n"," |-- salary: long (nullable = true)\n"," |-- date: timestamp (nullable = true)\n","\n"]}],"source":["correctedType_df.printSchema()"]},{"cell_type":"code","execution_count":18,"id":"d2dc9c4e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----+-----+------+-------------------+\n","| id|name| dept|salary|               date|\n","+---+----+-----+------+-------------------+\n","|  1| FFF|dept2|  7200|2015-04-14 19:32:33|\n","|  2| EEE|dept2|  8000|2016-01-11 05:52:43|\n","|  3| LLL|dept5|  3400|2016-09-11 00:00:00|\n","|  4| KKK|dept5|  3400|2016-09-11 05:52:43|\n","|  5| HHH|dept3|  3700|2016-09-25 15:32:33|\n","|  6| CCC|dept1|  3000|2017-06-05 01:02:13|\n","|  7| III|dept3|  4500|2017-10-15 15:22:23|\n","|  8| BBB|dept1|  1100|2018-04-01 05:12:03|\n","|  9| JJJ|dept5|  3400|2018-12-17 15:14:17|\n","| 10| AAA|dept1|  1000|2019-02-01 15:12:13|\n","| 11| GGG|dept3|  7100|2019-02-21 15:42:43|\n","| 12| MMM|dept3|  7100|2019-02-28 15:42:43|\n","| 13| DDD|dept1|  1500|2019-08-10 10:52:53|\n","+---+----+-----+------+-------------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["correctedType_df.orderBy('date', ascending=True).show()"]},{"cell_type":"code","execution_count":19,"id":"c931b5b3","metadata":{},"outputs":[],"source":["orderedDate_df = correctedType_df.orderBy('date', ascending=True)"]},{"cell_type":"code","execution_count":20,"id":"d982b7e3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----+-----+------+-------------------+--------+\n","| id|name| dept|salary|               date|datediff|\n","+---+----+-----+------+-------------------+--------+\n","|  1| FFF|dept2|  7200|2015-04-14 19:32:33|    2465|\n","|  2| EEE|dept2|  8000|2016-01-11 05:52:43|    2193|\n","|  3| LLL|dept5|  3400|2016-09-11 00:00:00|    1949|\n","|  4| KKK|dept5|  3400|2016-09-11 05:52:43|    1949|\n","|  5| HHH|dept3|  3700|2016-09-25 15:32:33|    1935|\n","|  6| CCC|dept1|  3000|2017-06-05 01:02:13|    1682|\n","|  7| III|dept3|  4500|2017-10-15 15:22:23|    1550|\n","|  8| BBB|dept1|  1100|2018-04-01 05:12:03|    1382|\n","|  9| JJJ|dept5|  3400|2018-12-17 15:14:17|    1122|\n","| 10| AAA|dept1|  1000|2019-02-01 15:12:13|    1076|\n","| 11| GGG|dept3|  7100|2019-02-21 15:42:43|    1056|\n","| 12| MMM|dept3|  7100|2019-02-28 15:42:43|    1049|\n","| 13| DDD|dept1|  1500|2019-08-10 10:52:53|     886|\n","+---+----+-----+------+-------------------+--------+\n","\n"]}],"source":["(\n","    orderedDate_df\n","    .withColumn('datediff', F.datediff(\n","        F.current_date(), F.col('date')\n","    ))\n","    .show()\n",")"]},{"cell_type":"code","execution_count":21,"id":"fb6653fd","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----+-----+------+-------------------+-----------+------------+\n","| id|name| dept|salary|               date|day_of_week|week_of_year|\n","+---+----+-----+------+-------------------+-----------+------------+\n","|  1| FFF|dept2|  7200|2015-04-14 19:32:33|          3|          16|\n","|  2| EEE|dept2|  8000|2016-01-11 05:52:43|          2|           2|\n","|  3| LLL|dept5|  3400|2016-09-11 00:00:00|          1|          36|\n","|  4| KKK|dept5|  3400|2016-09-11 05:52:43|          1|          36|\n","|  5| HHH|dept3|  3700|2016-09-25 15:32:33|          1|          38|\n","|  6| CCC|dept1|  3000|2017-06-05 01:02:13|          2|          23|\n","|  7| III|dept3|  4500|2017-10-15 15:22:23|          1|          41|\n","|  8| BBB|dept1|  1100|2018-04-01 05:12:03|          1|          13|\n","|  9| JJJ|dept5|  3400|2018-12-17 15:14:17|          2|          51|\n","| 10| AAA|dept1|  1000|2019-02-01 15:12:13|          6|           5|\n","| 11| GGG|dept3|  7100|2019-02-21 15:42:43|          5|           8|\n","| 12| MMM|dept3|  7100|2019-02-28 15:42:43|          5|           9|\n","| 13| DDD|dept1|  1500|2019-08-10 10:52:53|          7|          32|\n","+---+----+-----+------+-------------------+-----------+------------+\n","\n"]}],"source":["(\n","    orderedDate_df\n","    .withColumn('day_of_week', F.dayofweek(F.col('date')))\n","    .withColumn('week_of_year', F.weekofyear(F.col('date')))\n","    .show()\n",")"]},{"cell_type":"code","execution_count":null,"id":"8bafc071","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}